{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import IPython\n",
    "import copy\n",
    "from shutil import copyfile\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.dont_write_bytecode=True\n",
    "\n",
    "PACKAGE_PARENT = '../'\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser('__file__'))))\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "\n",
    "from influence.inceptionModel import BinaryInceptionModel\n",
    "from influence.logisticRegressionWithLBFGS import LogisticRegressionWithLBFGS\n",
    "import influence.experiments\n",
    "from influence.dataset import DataSet\n",
    "# from influence.dataset_poisoning import iterative_attack, select_examples_to_attack, get_projection_to_box_around_orig_point, generate_inception_features\n",
    "from influence.iter_attack import iterative_attack, select_examples_to_attack, get_projection_to_box_around_orig_point, generate_inception_features\n",
    "from influence.Progress import *\n",
    "\n",
    "from load_animals import *\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data_poisoning import data_poisoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selected = ['dog', 'fish']\n",
    "num_train_ex_per_class, num_test_ex_per_class = 900, 300\n",
    "use_IF = True\n",
    "target_test_idx = [45]\n",
    "num_to_perterb = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading animals from disk...\n",
      "../data/dataset_dog-fish_train-900_test-300.npz\n"
     ]
    }
   ],
   "source": [
    "# Find the cleaned dataset\n",
    "data_sets = load_animals(\n",
    "                    num_train_ex_per_class=num_train_ex_per_class, \n",
    "                    num_test_ex_per_class=num_test_ex_per_class,\n",
    "                    classes=data_selected)\n",
    "\n",
    "img_side = 299\n",
    "num_channels = 3\n",
    " \n",
    "initial_learning_rate = 0.001 \n",
    "keep_probs = None\n",
    "decay_epochs = [1000, 10000]\n",
    "\n",
    "weight_decay = 0.001\n",
    "\n",
    "num_classes = len(data_selected)\n",
    "max_lbfgs_iter = 1000\n",
    "batch_size = 50\n",
    "\n",
    "dataset_name = 'transferbility_%s_%s' % (num_train_ex_per_class, num_test_ex_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.logits Tensor(\"Shape:0\", shape=(2,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:191 -   get_vec_to_list_fn() ] Total number of parameters: 1536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong_labels_bool Tensor(\"Shape_2:0\", shape=(2,), dtype=int32)\n",
      "logits Tensor(\"Shape_3:0\", shape=(2,), dtype=int32)\n",
      "inception_features:  Tensor(\"flatten/Reshape:0\", shape=(?, ?), dtype=float32)\n",
      "x_poison_features:  Tensor(\"Gather:0\", shape=(1, ?), dtype=float32)\n",
      "t_target_features:  Tensor(\"Gather_1:0\", shape=(1, ?), dtype=float32)\n",
      "Lp:  Tensor(\"norm/Squeeze:0\", shape=(), dtype=float32)\n",
      "LP_gradient Tensor(\"strided_slice_1:0\", shape=(268203,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# InceptionResNet\n",
    "full_graph = tf.Graph()\n",
    "with full_graph.as_default():\n",
    "    full_model_name = '%s_inceptionRes_wd-%s' % (dataset_name, weight_decay)\n",
    "    full_model = BinaryInceptionModel(\n",
    "        img_side=img_side,\n",
    "        num_channels=num_channels,\n",
    "        weight_decay=weight_decay,\n",
    "        use_InceptionResNet=True,\n",
    "        num_classes=num_classes, \n",
    "        batch_size=batch_size,\n",
    "        data_sets=data_sets,\n",
    "        initial_learning_rate=initial_learning_rate,\n",
    "        keep_probs=keep_probs,\n",
    "        decay_epochs=decay_epochs,\n",
    "        mini_batch=True,\n",
    "        train_dir='output',\n",
    "        log_dir='log',\n",
    "        model_name=full_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: [0.01579112]\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: [0.00576179]\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: [0.02447189]\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  [1.]\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   [0.99166667]\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 2.501867e-06\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.4786887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.17748275, 0.06460591, 0.08047303, ..., 0.00543467, 0.05926711,\n",
       "       0.03573376], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.retrain_and_get_weights(data_sets.train.x, data_sets.train.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:influence_env]",
   "language": "python",
   "name": "conda-env-influence_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
