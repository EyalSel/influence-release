{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import IPython\n",
    "import copy\n",
    "from shutil import copyfile\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.dont_write_bytecode=True\n",
    "\n",
    "PACKAGE_PARENT = '../'\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser('__file__'))))\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "\n",
    "from influence.inceptionModel import BinaryInceptionModel\n",
    "from influence.logisticRegressionWithLBFGS import LogisticRegressionWithLBFGS\n",
    "import influence.experiments\n",
    "from influence.dataset import DataSet\n",
    "# from influence.dataset_poisoning import iterative_attack, select_examples_to_attack, get_projection_to_box_around_orig_point, generate_inception_features\n",
    "from influence.iter_attack import iterative_attack, select_examples_to_attack, get_projection_to_box_around_orig_point, generate_inception_features\n",
    "from influence.Progress import *\n",
    "\n",
    "from load_animals import *\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data_poisoning import data_poisoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selected = ['dog', 'fish']\n",
    "num_train_ex_per_class, num_test_ex_per_class = 900, 300\n",
    "use_IF = True\n",
    "target_test_idx = [45]\n",
    "num_to_perterb = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading animals from disk...\n",
      "../data/dataset_dog-fish_train-900_test-300.npz\n",
      "*** Full:\n",
      "self.logits Tensor(\"Shape:0\", shape=(2,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:191 -   get_vec_to_list_fn() ] Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong_labels_bool Tensor(\"Shape_2:0\", shape=(2,), dtype=int32)\n",
      "logits Tensor(\"Shape_3:0\", shape=(2,), dtype=int32)\n",
      "inception_features:  Tensor(\"flatten/Reshape:0\", shape=(?, ?), dtype=float32)\n",
      "x_poison_features:  Tensor(\"Gather:0\", shape=(1, ?), dtype=float32)\n",
      "t_target_features:  Tensor(\"Gather_1:0\", shape=(1, ?), dtype=float32)\n",
      "Lp:  Tensor(\"norm/Squeeze:0\", shape=(), dtype=float32)\n",
      "LP_gradient Tensor(\"strided_slice_1:0\", shape=(268203,), dtype=float32)\n",
      "*** Top:\n",
      "self.logits Tensor(\"Shape:0\", shape=(2,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:191 -   get_vec_to_list_fn() ] Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong_labels_bool Tensor(\"Shape_2:0\", shape=(2,), dtype=int32)\n",
      "logits Tensor(\"Shape_3:0\", shape=(2,), dtype=int32)\n",
      "Using normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012129042\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0039761304\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.048454043\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 3.6090535e-07\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.0380473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [41] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: [0.01212904]\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: [0.00397613]\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: [0.04845405]\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  [1.]\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   [0.985]\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 3.601115e-07\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.0380473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating poisoned dataset...\n",
      "('step_size is', 0.02)\n",
      "****** Attacking test_idx [45] ******\n",
      "Total number of parameters: 2048\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.724119\n",
      "         Iterations: 8\n",
      "         Function evaluations: 70\n",
      "         Gradient evaluations: 66\n",
      "         Hessian evaluations: 49\n",
      "Inverse HVP took 1.96392798424 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000478982925415 sec\n",
      "Entering the for loop\n",
      "finished calculating grad_wrt_input_val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:113 -     iterative_attack() ] Test idx: [45], Indices to poison: [1141], train label: [1.], test labels: [0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('all_indices_to_poison: ', array([1141]))\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:123 -     iterative_attack() ] Initial Test pred (full): [[0.99281716 0.00718284]]\n",
      "[iter_attack.py:126 -     iterative_attack() ] Initial Test pred (top): [[0.99281716 0.00718284]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 0 perturbation shape: (1, 268203), perturbation: [[-0.00040251  0.00463659 -0.00554925 ... -0.00173009  0.00069042\n",
      "   0.00073988]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2.724119\n",
      "         Iterations: 8\n",
      "         Function evaluations: 70\n",
      "         Gradient evaluations: 66\n",
      "         Hessian evaluations: 49\n",
      "Inverse HVP took 2.0469250679 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000542163848877 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012137257\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004008635\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04845028\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0007486059\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.0320277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [35] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.9913946  0.00860544]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.9913946  0.00860544]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 1 perturbation shape: (1, 268203), perturbation: [[-3.44394334e-03  5.75287361e-03 -3.15112295e-03 ...  3.34246870e-04\n",
      "   1.47601089e-03  4.19109128e-05]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -3.910356\n",
      "         Iterations: 9\n",
      "         Function evaluations: 85\n",
      "         Gradient evaluations: 82\n",
      "         Hessian evaluations: 54\n",
      "Inverse HVP took 2.30622005463 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000557899475098 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [33] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.0121528\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004037302\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.048265513\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.001287035\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.028771\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.9899418  0.01005824]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.9899418  0.01005824]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 2 perturbation shape: (1, 268203), perturbation: [[-0.00299321  0.00179159 -0.00218879 ...  0.000241    0.0013077\n",
      "  -0.0006756 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -5.338054\n",
      "         Iterations: 8\n",
      "         Function evaluations: 84\n",
      "         Gradient evaluations: 80\n",
      "         Hessian evaluations: 52\n",
      "Inverse HVP took 2.26977300644 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000525951385498 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [37] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.0121652\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0040528174\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.048029542\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0015440258\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.027998\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.98837787 0.01162213]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.98837787 0.01162213]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 3 perturbation shape: (1, 268203), perturbation: [[ 0.00361042  0.01009976  0.003493   ... -0.00271438  0.00254462\n",
      "  -0.00203661]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -7.118159\n",
      "         Iterations: 8\n",
      "         Function evaluations: 107\n",
      "         Gradient evaluations: 103\n",
      "         Hessian evaluations: 71\n",
      "Inverse HVP took 3.14777112007 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.00051212310791 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.0121696405\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0040515102\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04769071\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0014933395\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.029424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [33] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.9865927  0.01340731]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.9865927  0.01340731]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 4 perturbation shape: (1, 268203), perturbation: [[-0.00032509  0.00459522  0.0020139  ...  0.00694416 -0.0024155\n",
      "  -0.0006726 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -9.454767\n",
      "         Iterations: 7\n",
      "         Function evaluations: 152\n",
      "         Gradient evaluations: 145\n",
      "         Hessian evaluations: 57\n",
      "Inverse HVP took 3.69706106186 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000540971755981 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012170084\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004039942\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.047437303\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0012496863\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.0324044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [36] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.9845248  0.01547524]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.9845248  0.01547524]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 5 perturbation shape: (1, 268203), perturbation: [[ 0.0017003   0.00043269 -0.00329814 ... -0.00106907  0.0030953\n",
      "  -0.00400737]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -12.565337\n",
      "         Iterations: 9\n",
      "         Function evaluations: 79\n",
      "         Gradient evaluations: 76\n",
      "         Hessian evaluations: 68\n",
      "Inverse HVP took 2.3396551609 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000537157058716 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012167926\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004017392\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.047112044\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.00077574735\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.037458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [37] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.982084   0.01791597]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.982084   0.01791597]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 6 perturbation shape: (1, 268203), perturbation: [[ 4.60306322e-03  6.60786033e-03  8.98574479e-03 ... -6.58529112e-03\n",
      "   1.77842448e-05  1.64268119e-03]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -16.789364\n",
      "         Iterations: 9\n",
      "         Function evaluations: 84\n",
      "         Gradient evaluations: 81\n",
      "         Hessian evaluations: 67\n",
      "Inverse HVP took 2.43664002419 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000525951385498 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012173511\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0039992193\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.046750125\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.00042406985\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.0433383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [37] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.97927654 0.02072353]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.97927654 0.02072353]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 7 perturbation shape: (1, 268203), perturbation: [[-0.00608186 -0.00397287  0.00261679 ... -0.02168598  0.00841436\n",
      "  -0.00108196]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -22.387442\n",
      "         Iterations: 7\n",
      "         Function evaluations: 92\n",
      "         Gradient evaluations: 87\n",
      "         Hessian evaluations: 52\n",
      "Inverse HVP took 2.40756511688 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000517129898071 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012185224\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.003984526\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.046422698\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0005242118\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.0498633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [41] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.9758488  0.02415115]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.9758488  0.02415115]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 8 perturbation shape: (1, 268203), perturbation: [[ 0.00373405  0.00420644  0.00629798 ... -0.016609    0.00719546\n",
      "   0.00143329]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -30.287529\n",
      "         Iterations: 7\n",
      "         Function evaluations: 92\n",
      "         Gradient evaluations: 88\n",
      "         Hessian evaluations: 49\n",
      "Inverse HVP took 2.38524198532 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000534057617188 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012209769\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.00397485\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04599846\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.000986726\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.058305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [42] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.9714965  0.02850356]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.9714965  0.02850356]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 9 perturbation shape: (1, 268203), perturbation: [[-0.00982578  0.00675172  0.00775319 ... -0.03630863  0.01978429\n",
      "  -0.00973171]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -41.989285\n",
      "         Iterations: 7\n",
      "         Function evaluations: 70\n",
      "         Gradient evaluations: 66\n",
      "         Hessian evaluations: 50\n",
      "Inverse HVP took 2.11752605438 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000520944595337 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012244582\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.003973145\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.045600392\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0014348126\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.0672927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [44] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.9662371  0.03376281]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.9662371  0.03376281]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 10 perturbation shape: (1, 268203), perturbation: [[ 0.00704491  0.0155382   0.01393127 ... -0.02303072  0.00419543\n",
      "   0.00623875]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -58.618126\n",
      "         Iterations: 8\n",
      "         Function evaluations: 142\n",
      "         Gradient evaluations: 135\n",
      "         Hessian evaluations: 57\n",
      "Inverse HVP took 3.48494410515 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000532865524292 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012287385\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0039781425\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.045151014\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0018289918\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.076578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [42] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.95937496 0.04062495]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.95937496 0.04062495]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 11 perturbation shape: (1, 268203), perturbation: [[-0.02438919  0.02719402  0.03993858 ... -0.09246016  0.046726\n",
      "  -0.01762302]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -84.359711\n",
      "         Iterations: 8\n",
      "         Function evaluations: 75\n",
      "         Gradient evaluations: 72\n",
      "         Hessian evaluations: 56\n",
      "Inverse HVP took 2.14573907852 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000581979751587 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012327701\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.003987638\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.044831872\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.002089409\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.0841312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [44] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.95123243 0.04876753]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.95123243 0.04876753]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 12 perturbation shape: (1, 268203), perturbation: [[-0.0486811   0.02979195  0.05845137 ... -0.04320905  0.05000476\n",
      "  -0.02613031]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -120.808266\n",
      "         Iterations: 9\n",
      "         Function evaluations: 87\n",
      "         Gradient evaluations: 84\n",
      "         Hessian evaluations: 58\n",
      "Inverse HVP took 2.40206098557 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.00053596496582 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012375306\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0039994856\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.044434015\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0023436146\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.092877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [41] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.9413071  0.05869287]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.9413071  0.05869287]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 13 perturbation shape: (1, 268203), perturbation: [[-0.03640124  0.03624121  0.06862709 ... -0.11853473  0.04996787\n",
      "  -0.01418777]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -173.823944\n",
      "         Iterations: 8\n",
      "         Function evaluations: 82\n",
      "         Gradient evaluations: 78\n",
      "         Hessian evaluations: 52\n",
      "Inverse HVP took 2.22313690186 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000530004501343 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012423951\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004013426\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.044125013\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.002585384\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.101347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [45] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.92934406 0.07065597]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.92934406 0.07065597]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 14 perturbation shape: (1, 268203), perturbation: [[-0.08167166  0.0196423   0.04080606 ... -0.12820826  0.09091587\n",
      "  -0.00842227]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -250.346283\n",
      "         Iterations: 6\n",
      "         Function evaluations: 71\n",
      "         Gradient evaluations: 65\n",
      "         Hessian evaluations: 33\n",
      "Inverse HVP took 1.83521103859 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000524997711182 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012475803\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004029912\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04372413\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0027830624\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.109961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [44] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.9164007  0.08359933]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.9164007  0.08359933]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 15 perturbation shape: (1, 268203), perturbation: [[ 0.00624521  0.07466733  0.07262975 ... -0.17463592  0.08863921\n",
      "  -0.01473148]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -348.123779\n",
      "         Iterations: 7\n",
      "         Function evaluations: 78\n",
      "         Gradient evaluations: 73\n",
      "         Hessian evaluations: 39\n",
      "Inverse HVP took 1.99044108391 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000528812408447 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012522837\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004045649\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.043524746\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0029506886\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.1175694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [47] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.90050215 0.0994979 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.90050215 0.0994979 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 16 perturbation shape: (1, 268203), perturbation: [[-0.04497076  0.1058852   0.03673159 ... -0.16876455  0.05612329\n",
      "   0.02438908]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -489.928497\n",
      "         Iterations: 9\n",
      "         Function evaluations: 81\n",
      "         Gradient evaluations: 79\n",
      "         Hessian evaluations: 56\n",
      "Inverse HVP took 2.27328300476 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000536918640137 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012563883\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0040611792\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.043106917\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0030520463\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.123762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [35] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.88183415 0.11816579]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.88183415 0.11816579]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 17 perturbation shape: (1, 268203), perturbation: [[ 0.06709924  0.13198632  0.08400795 ... -0.16113156  0.18436739\n",
      "  -0.10068114]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -686.136963\n",
      "         Iterations: 7\n",
      "         Function evaluations: 89\n",
      "         Gradient evaluations: 84\n",
      "         Hessian evaluations: 38\n",
      "Inverse HVP took 2.35592412949 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000509023666382 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012615485\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0040794928\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.043058585\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0032264297\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.131825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [44] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.8606557 0.1393443]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.8606557 0.1393443]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 18 perturbation shape: (1, 268203), perturbation: [[-0.17270136  0.02670966  0.0406675  ... -0.20206077  0.06128348\n",
      "   0.06572253]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -947.803833\n",
      "         Iterations: 8\n",
      "         Function evaluations: 131\n",
      "         Gradient evaluations: 123\n",
      "         Hessian evaluations: 47\n",
      "Inverse HVP took 3.15906095505 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000515937805176 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012658032\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0040957895\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04272229\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0033171298\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.1381745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [42] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.837788   0.16221195]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.837788   0.16221195]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 19 perturbation shape: (1, 268203), perturbation: [[ 0.18237302  0.19434002  0.06755204 ... -0.46328622  0.27841794\n",
      "  -0.08741245]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1276.079712\n",
      "         Iterations: 9\n",
      "         Function evaluations: 86\n",
      "         Gradient evaluations: 83\n",
      "         Hessian evaluations: 60\n",
      "Inverse HVP took 2.3755800724 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.00052285194397 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012701694\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004111786\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.042753626\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0034497096\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.144854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [39] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.81202906 0.18797089]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.81202906 0.18797089]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 20 perturbation shape: (1, 268203), perturbation: [[-0.24860036 -0.00144222 -0.03020179 ... -0.00872377 -0.02961512\n",
      "   0.08360916]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1702.779297\n",
      "         Iterations: 8\n",
      "         Function evaluations: 70\n",
      "         Gradient evaluations: 66\n",
      "         Hessian evaluations: 43\n",
      "Inverse HVP took 1.90557813644 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000526905059814 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012736208\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0041259443\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.042377982\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.003502025\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.1497617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [39] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.78427166 0.21572836]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.78427166 0.21572836]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 21 perturbation shape: (1, 268203), perturbation: [[ 0.19216122  0.27866495  0.15058529 ... -0.68883884  0.46573779\n",
      "  -0.07183742]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2227.222168\n",
      "         Iterations: 10\n",
      "         Function evaluations: 83\n",
      "         Gradient evaluations: 81\n",
      "         Hessian evaluations: 62\n",
      "Inverse HVP took 2.53632998466 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000519037246704 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012786485\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004143708\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.042401467\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0036552264\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.15759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [44] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.7522847  0.24771532]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.7522847  0.24771532]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 22 perturbation shape: (1, 268203), perturbation: [[-0.33730906 -0.10067859 -0.10701646 ... -0.64205432  0.06219681\n",
      "   0.3063648 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -2918.786133\n",
      "         Iterations: 7\n",
      "         Function evaluations: 92\n",
      "         Gradient evaluations: 88\n",
      "         Hessian evaluations: 35\n",
      "Inverse HVP took 2.22858810425 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000554084777832 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012818214\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0041574957\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.041961126\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0036918293\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.161903\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.7163812  0.28361884]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.7163812  0.28361884]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [46] iter.\n",
      "After training with LBFGS: \n",
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 23 perturbation shape: (1, 268203), perturbation: [[ 0.13768823  0.53800583  0.32251304 ... -0.24774499  0.35522524\n",
      "  -0.32467222]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -3795.286377\n",
      "         Iterations: 11\n",
      "         Function evaluations: 22\n",
      "         Gradient evaluations: 32\n",
      "         Hessian evaluations: 73\n",
      "Inverse HVP took 1.35176491737 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000524997711182 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012857677\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004171959\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.042120513\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0038220421\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.167906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [46] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.6807738 0.3192262]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.6807738 0.3192262]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 24 perturbation shape: (1, 268203), perturbation: [[-0.22281629 -0.03789485 -0.04859094 ... -0.77855581 -0.11851424\n",
      "   0.56888437]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -4781.223633\n",
      "         Iterations: 10\n",
      "         Function evaluations: 147\n",
      "         Gradient evaluations: 142\n",
      "         Hessian evaluations: 44\n",
      "Inverse HVP took 3.46636199951 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000519990921021 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012892339\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0041869855\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.041785274\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.003850368\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.1726136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [43] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.63954973 0.3604503 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.63954973 0.3604503 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 25 perturbation shape: (1, 268203), perturbation: [[ 0.29913256  0.97576463  0.52214289 ... -1.2030437   0.32041776\n",
      "  -0.05278853]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -6049.940918\n",
      "         Iterations: 9\n",
      "         Function evaluations: 81\n",
      "         Gradient evaluations: 79\n",
      "         Hessian evaluations: 46\n",
      "Inverse HVP took 2.16485309601 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000530958175659 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.0129297245\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004200297\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.041954372\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.003985379\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.1783795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [41] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.6037117  0.39628834]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.6037117  0.39628834]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 26 perturbation shape: (1, 268203), perturbation: [[-0.37263453 -0.22583529 -0.09539194 ... -0.42055139 -0.15942286\n",
      "   0.42093462]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -7280.092773\n",
      "         Iterations: 10\n",
      "         Function evaluations: 101\n",
      "         Gradient evaluations: 100\n",
      "         Hessian evaluations: 47\n",
      "Inverse HVP took 2.75426387787 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000508069992065 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012941645\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0042065806\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.041643422\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0039569815\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.179728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [29] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.5686512  0.43134877]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.5686512  0.43134877]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 27 perturbation shape: (1, 268203), perturbation: [[ 0.64307749  0.82905686 -0.22048378 ... -1.14418268  0.24836169\n",
      "   0.32765454]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -8571.640625\n",
      "         Iterations: 9\n",
      "         Function evaluations: 83\n",
      "         Gradient evaluations: 80\n",
      "         Hessian evaluations: 46\n",
      "Inverse HVP took 2.1878888607 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000514984130859 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012987401\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004222937\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.041926395\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004122546\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.186756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [35] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.5406736 0.4593264]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.5406736 0.4593264]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 28 perturbation shape: (1, 268203), perturbation: [[-0.74416351  0.54348058  0.65830678 ... -0.0813143   0.02298173\n",
      "   0.45600045]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -9693.134766\n",
      "         Iterations: 8\n",
      "         Function evaluations: 51\n",
      "         Gradient evaluations: 48\n",
      "         Hessian evaluations: 41\n",
      "Inverse HVP took 1.46305990219 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000530004501343 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.012999951\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0042294357\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04155428\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004071583\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.188201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [38] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.50573087 0.49426913]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.50573087 0.49426913]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 29 perturbation shape: (1, 268203), perturbation: [[ 0.68671191  0.14065012 -1.03864086 ... -1.22824419 -0.04210854\n",
      "   0.60368526]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -11149.628906\n",
      "         Iterations: 9\n",
      "         Function evaluations: 148\n",
      "         Gradient evaluations: 144\n",
      "         Hessian evaluations: 52\n",
      "Inverse HVP took 3.59793114662 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000533103942871 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013031796\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0042410786\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04191669\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.9833333333333333\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004196498\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.193022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [43] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.47785574 0.52214426]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.47785574 0.52214426]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 30 perturbation shape: (1, 268203), perturbation: [[-0.32352674  1.15790462  1.04992914 ... -0.6606974  -0.00959615\n",
      "   0.7582134 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -12417.662109\n",
      "         Iterations: 12\n",
      "         Function evaluations: 146\n",
      "         Gradient evaluations: 143\n",
      "         Hessian evaluations: 56\n",
      "Inverse HVP took 3.56912708282 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000509977340698 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013047023\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004247712\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04142009\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.9833333333333333\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004171339\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.195071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [35] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.44455808 0.5554419 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.44455808 0.5554419 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 31 perturbation shape: (1, 268203), perturbation: [[ 0.22219051  0.31891108 -0.45329082 ...  0.12031803 -0.28498173\n",
      "  -0.11089462]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -13962.597656\n",
      "         Iterations: 9\n",
      "         Function evaluations: 89\n",
      "         Gradient evaluations: 88\n",
      "         Hessian evaluations: 41\n",
      "Inverse HVP took 2.28506684303 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000515222549438 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013079586\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0042597977\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04197008\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.9833333333333333\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004287236\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.1999493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [46] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.4177006 0.5822994]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.4177006 0.5822994]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 32 perturbation shape: (1, 268203), perturbation: [[-0.57361639  0.65775919  0.62843502 ... -1.99631786  0.36651665\n",
      "   1.32867026]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -15318.808594\n",
      "         Iterations: 9\n",
      "         Function evaluations: 145\n",
      "         Gradient evaluations: 141\n",
      "         Hessian evaluations: 46\n",
      "Inverse HVP took 3.59503817558 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000519037246704 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013096746\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0042677145\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04161878\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.9833333333333333\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004276274\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.20215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [37] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.38599145 0.61400855]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.38599145 0.61400855]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 33 perturbation shape: (1, 268203), perturbation: [[-0.05627263  0.1485042  -0.39320326 ...  0.65860307 -0.42773303\n",
      "  -0.05731224]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -16920.183594\n",
      "         Iterations: 9\n",
      "         Function evaluations: 86\n",
      "         Gradient evaluations: 84\n",
      "         Hessian evaluations: 45\n",
      "Inverse HVP took 2.23834586143 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000523090362549 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [39] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013119793\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004276128\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.042214666\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.9833333333333333\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004362577\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2056303\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.35883525 0.6411647 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.35883525 0.6411647 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 34 perturbation shape: (1, 268203), perturbation: [[-0.08299148  1.13651943  0.94555962 ... -1.40302932  0.10372299\n",
      "   1.20507658]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -18401.195312\n",
      "         Iterations: 8\n",
      "         Function evaluations: 74\n",
      "         Gradient evaluations: 71\n",
      "         Hessian evaluations: 37\n",
      "Inverse HVP took 1.90918707848 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000517129898071 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [34] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013142636\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0042865966\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04181221\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.9833333333333333\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0043560574\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2085724\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.32947797 0.6705221 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.32947797 0.6705221 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 35 perturbation shape: (1, 268203), perturbation: [[-0.25360906 -0.05850579 -1.0907855  ...  0.06722155 -0.12490039\n",
      "   0.12210494]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -20008.351562\n",
      "         Iterations: 10\n",
      "         Function evaluations: 82\n",
      "         Gradient evaluations: 81\n",
      "         Hessian evaluations: 52\n",
      "Inverse HVP took 2.33808112144 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000543117523193 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013160432\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0042926064\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.042529125\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.9833333333333333\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0044351113\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2113714\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.30597728 0.6940227 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.30597728 0.6940227 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [36] iter.\n",
      "After training with LBFGS: \n",
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 36 perturbation shape: (1, 268203), perturbation: [[-0.69375777  1.34584498  1.88122571 ... -2.21478295 -0.08984178\n",
      "   1.53729653]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -21378.861328\n",
      "         Iterations: 8\n",
      "         Function evaluations: 77\n",
      "         Gradient evaluations: 74\n",
      "         Hessian evaluations: 38\n",
      "Inverse HVP took 2.05290484428 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000528812408447 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013182465\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004302797\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.042072333\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.9833333333333333\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004416642\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2141814\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.2830712 0.7169288]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.2830712 0.7169288]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [41] iter.\n",
      "After training with LBFGS: \n",
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 37 perturbation shape: (1, 268203), perturbation: [[-0.2521123   0.27493942 -0.77714598 ...  0.67310357 -0.59798944\n",
      "   0.13074911]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -22695.769531\n",
      "         Iterations: 9\n",
      "         Function evaluations: 82\n",
      "         Gradient evaluations: 79\n",
      "         Hessian evaluations: 50\n",
      "Inverse HVP took 2.24370503426 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000515937805176 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013207172\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004311044\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.0427399\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.9833333333333333\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004521747\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2180862\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.26700562 0.7329944 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.26700562 0.7329944 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [47] iter.\n",
      "After training with LBFGS: \n",
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 38 perturbation shape: (1, 268203), perturbation: [[-0.30347693  0.53000891  0.65806878 ... -1.67428601  0.26926652\n",
      "   1.63867545]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -23692.671875\n",
      "         Iterations: 11\n",
      "         Function evaluations: 143\n",
      "         Gradient evaluations: 141\n",
      "         Hessian evaluations: 74\n",
      "Inverse HVP took 3.75992798805 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000514984130859 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [35] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013225745\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0043197456\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.042365715\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.9833333333333333\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004496741\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2204266\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.2480489  0.75195104]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.2480489  0.75195104]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 39 perturbation shape: (1, 268203), perturbation: [[-0.13859864  0.64081669 -0.4043107  ... -0.02028691 -0.36675507\n",
      "  -0.05681396]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -24802.527344\n",
      "         Iterations: 11\n",
      "         Function evaluations: 20\n",
      "         Gradient evaluations: 30\n",
      "         Hessian evaluations: 81\n",
      "Inverse HVP took 1.38158392906 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000517845153809 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.0132449195\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004326004\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04295742\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.9833333333333333\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004587076\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2234855\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.2336445  0.76635545]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.2336445  0.76635545]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [40] iter.\n",
      "After training with LBFGS: \n",
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 40 perturbation shape: (1, 268203), perturbation: [[-0.13709736  0.33761454  0.2436018  ... -0.32009476  0.12659042\n",
      "   1.25877249]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -25728.074219\n",
      "         Iterations: 9\n",
      "         Function evaluations: 89\n",
      "         Gradient evaluations: 88\n",
      "         Hessian evaluations: 51\n",
      "Inverse HVP took 2.55220079422 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000512838363647 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013252289\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0043307673\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.042589728\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.9833333333333333\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0045445375\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.224103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [20] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.21906708 0.7809329 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.21906708 0.7809329 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 41 perturbation shape: (1, 268203), perturbation: [[-0.05361737  1.44835818  0.23036732 ... -1.30231845  0.22179019\n",
      "   0.20366859]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -26586.781250\n",
      "         Iterations: 8\n",
      "         Function evaluations: 94\n",
      "         Gradient evaluations: 90\n",
      "         Hessian evaluations: 37\n",
      "Inverse HVP took 2.32560110092 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000514984130859 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013275181\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.00433807\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.043225944\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004644547\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.227792\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.2076079 0.7923921]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.2076079 0.7923921]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [38] iter.\n",
      "After training with LBFGS: \n",
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 42 perturbation shape: (1, 268203), perturbation: [[ 0.26982522  0.69401944 -0.08195627 ... -0.31995529  0.25713545\n",
      "   0.76119637]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -27357.078125\n",
      "         Iterations: 11\n",
      "         Function evaluations: 253\n",
      "         Gradient evaluations: 246\n",
      "         Hessian evaluations: 59\n",
      "Inverse HVP took 5.8788819313 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000560998916626 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013287833\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0043446366\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.042828225\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0046043154\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.229231\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.19546485 0.80453515]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.19546485 0.80453515]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [36] iter.\n",
      "After training with LBFGS: \n",
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 43 perturbation shape: (1, 268203), perturbation: [[-0.48567361 -0.14591932 -1.35229206 ... -1.15288293  0.3324762\n",
      "   0.27509511]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -28059.542969\n",
      "         Iterations: 8\n",
      "         Function evaluations: 76\n",
      "         Gradient evaluations: 72\n",
      "         Hessian evaluations: 40\n",
      "Inverse HVP took 2.12812519073 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000545024871826 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.01329886\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0043480895\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.043453116\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0046849493\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.231021\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.18416443 0.81583554]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.18416443 0.81583554]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [37] iter.\n",
      "After training with LBFGS: \n",
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 44 perturbation shape: (1, 268203), perturbation: [[ 0.1111902   1.12053931  0.49228746 ... -0.89522201  1.1563139\n",
      "   0.99220872]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -28845.349609\n",
      "         Iterations: 8\n",
      "         Function evaluations: 102\n",
      "         Gradient evaluations: 99\n",
      "         Hessian evaluations: 43\n",
      "Inverse HVP took 2.54216504097 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000547885894775 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013319898\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0043574474\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04312384\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004656822\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.233781\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.17442094 0.82557905]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.17442094 0.82557905]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [38] iter.\n",
      "After training with LBFGS: \n",
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 45 perturbation shape: (1, 268203), perturbation: [[-0.63437665  0.90039378 -0.16940838 ... -2.10685492  0.00641549\n",
      "   0.65393519]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -29402.234375\n",
      "         Iterations: 10\n",
      "         Function evaluations: 83\n",
      "         Gradient evaluations: 81\n",
      "         Hessian evaluations: 60\n",
      "Inverse HVP took 2.4059009552 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000532150268555 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [22] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013321927\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0043568923\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.043606747\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0047238097\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2343907\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.16573903 0.83426094]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.16573903 0.83426094]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 46 perturbation shape: (1, 268203), perturbation: [[0.29397005 1.53292191 0.702398   ... 0.14300187 0.48648024 0.59275502]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -30014.945312\n",
      "         Iterations: 8\n",
      "         Function evaluations: 91\n",
      "         Gradient evaluations: 87\n",
      "         Hessian evaluations: 39\n",
      "Inverse HVP took 2.47348093987 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000523090362549 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [43] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013339542\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0043653627\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04336588\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004697535\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2365503\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.15718588 0.8428141 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.15718588 0.8428141 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 47 perturbation shape: (1, 268203), perturbation: [[-0.43439415  1.15958309 -0.06881319 ... -2.72028089  0.58187127\n",
      "   0.29553366]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -30516.498047\n",
      "         Iterations: 11\n",
      "         Function evaluations: 137\n",
      "         Gradient evaluations: 133\n",
      "         Hessian evaluations: 63\n",
      "Inverse HVP took 3.49434995651 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000552892684937 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013342263\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0043649334\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04386354\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0047691693\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2372937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [36] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.15125437 0.84874564]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.15125437 0.84874564]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 48 perturbation shape: (1, 268203), perturbation: [[-0.46964109  0.22227633  0.08689654 ...  0.54207188  0.29586589\n",
      "   0.89865887]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -30938.408203\n",
      "         Iterations: 10\n",
      "         Function evaluations: 208\n",
      "         Gradient evaluations: 202\n",
      "         Hessian evaluations: 48\n",
      "Inverse HVP took 4.78606796265 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000538110733032 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013358692\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004373343\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.043587342\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004729811\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2391853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [38] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.14421001 0.85579   ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.14421001 0.85579   ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 49 perturbation shape: (1, 268203), perturbation: [[ 0.50157952  1.0276469  -0.39456099 ... -1.59019887  0.05566478\n",
      "  -0.02085829]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -31365.402344\n",
      "         Iterations: 9\n",
      "         Function evaluations: 82\n",
      "         Gradient evaluations: 79\n",
      "         Hessian evaluations: 49\n",
      "Inverse HVP took 2.39031100273 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000560998916626 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013356229\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0043711634\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.044029742\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0047808457\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2391195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [19] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.13873288 0.8612672 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.13873288 0.8612672 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 50 perturbation shape: (1, 268203), perturbation: [[-1.23754692  0.93988359  1.32329345 ... -3.36186433  1.56250691\n",
      "   0.70982558]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -31732.087891\n",
      "         Iterations: 9\n",
      "         Function evaluations: 86\n",
      "         Gradient evaluations: 85\n",
      "         Hessian evaluations: 49\n",
      "Inverse HVP took 2.28760194778 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000526189804077 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013379566\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004382121\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.043821145\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0047757975\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2420387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [36] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.1318178 0.8681822]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.1318178 0.8681822]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 51 perturbation shape: (1, 268203), perturbation: [[ 0.97204179  1.43500221 -0.91591746 ...  0.46775088 -0.10592794\n",
      "   0.05534968]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -32158.414062\n",
      "         Iterations: 7\n",
      "         Function evaluations: 82\n",
      "         Gradient evaluations: 77\n",
      "         Hessian evaluations: 33\n",
      "Inverse HVP took 2.01453089714 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000525951385498 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013367878\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004376455\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.044276327\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004794678\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.240619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [23] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.12713705 0.872863  ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.12713705 0.872863  ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 52 perturbation shape: (1, 268203), perturbation: [[-1.44301236  1.01452947  2.00310922 ... -3.62376547  0.92134076\n",
      "   0.78340352]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -32476.824219\n",
      "         Iterations: 11\n",
      "         Function evaluations: 89\n",
      "         Gradient evaluations: 88\n",
      "         Hessian evaluations: 62\n",
      "Inverse HVP took 2.4922311306 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000514984130859 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013400524\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0043906644\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.044015255\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004808543\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2449636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [44] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.12032991 0.8796701 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.12032991 0.8796701 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 53 perturbation shape: (1, 268203), perturbation: [[ 1.36120629  1.70143318 -0.5477857  ...  0.89315277 -0.11426965\n",
      "  -0.01437544]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -32891.085938\n",
      "         Iterations: 9\n",
      "         Function evaluations: 78\n",
      "         Gradient evaluations: 75\n",
      "         Hessian evaluations: 46\n",
      "Inverse HVP took 2.19204688072 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000602006912231 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013386797\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0043842173\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.044532992\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0048387074\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2432485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [30] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.11610889 0.88389105]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.11610889 0.88389105]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 54 perturbation shape: (1, 268203), perturbation: [[-1.71391892  0.94645262  1.79786384 ... -4.84827662  1.6854372\n",
      "   1.07627368]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -33182.140625\n",
      "         Iterations: 10\n",
      "         Function evaluations: 227\n",
      "         Gradient evaluations: 220\n",
      "         Hessian evaluations: 49\n",
      "Inverse HVP took 5.123513937 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000511169433594 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.01342147\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0043989657\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.0441459\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004841016\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.247942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [42] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.11155002 0.88844997]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.11155002 0.88844997]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 55 perturbation shape: (1, 268203), perturbation: [[ 0.45831469  1.51082134 -0.20610929 ...  0.02990631 -0.0561462\n",
      "  -0.35419327]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -33457.156250\n",
      "         Iterations: 8\n",
      "         Function evaluations: 78\n",
      "         Gradient evaluations: 75\n",
      "         Hessian evaluations: 39\n",
      "Inverse HVP took 2.02020812035 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000527143478394 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013408396\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004392752\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.044702612\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0048889196\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.246326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [19] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.1084337 0.8915663]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.1084337 0.8915663]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 56 perturbation shape: (1, 268203), perturbation: [[-0.81779575  1.51009917  2.1708889  ... -3.0304575   1.02664256\n",
      "   1.43102431]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -33695.156250\n",
      "         Iterations: 11\n",
      "         Function evaluations: 94\n",
      "         Gradient evaluations: 93\n",
      "         Hessian evaluations: 59\n",
      "Inverse HVP took 2.57813811302 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000529050827026 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013431052\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044032116\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04429577\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004853241\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2491975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [34] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.10399538 0.89600456]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.10399538 0.89600456]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 57 perturbation shape: (1, 268203), perturbation: [[-0.59997344  1.8172183   0.74397182 ... -1.72256565  1.12828755\n",
      "  -1.30766344]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -33935.984375\n",
      "         Iterations: 9\n",
      "         Function evaluations: 80\n",
      "         Gradient evaluations: 78\n",
      "         Hessian evaluations: 42\n",
      "Inverse HVP took 2.10016012192 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.00054407119751 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013427112\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004400542\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.044827722\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0049156738\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.248898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [19] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.101248   0.89875203]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.101248   0.89875203]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 58 perturbation shape: (1, 268203), perturbation: [[-0.16119218  1.61579561  1.64500463 ...  0.77268463 -0.74608612\n",
      "   2.15534043]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -34160.351562\n",
      "         Iterations: 9\n",
      "         Function evaluations: 79\n",
      "         Gradient evaluations: 76\n",
      "         Hessian evaluations: 46\n",
      "Inverse HVP took 2.12116098404 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.00052285194397 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013445519\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004409137\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.0444623\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0048777247\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2512074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [36] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.09749784 0.9025022 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.09749784 0.9025022 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 59 perturbation shape: (1, 268203), perturbation: [[-0.38529843  0.96180868  0.00612538 ... -3.16781473  2.01932788\n",
      "  -0.45468688]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -34339.601562\n",
      "         Iterations: 8\n",
      "         Function evaluations: 89\n",
      "         Gradient evaluations: 86\n",
      "         Hessian evaluations: 38\n",
      "Inverse HVP took 2.23154592514 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000514030456543 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.0134468675\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044088135\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04499975\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004951398\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.251601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [35] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.09487468 0.9051253 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.09487468 0.9051253 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 60 perturbation shape: (1, 268203), perturbation: [[-1.05365872  0.89208132  0.61291909 ... -0.2975294  -1.67494774\n",
      "   1.87966943]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -34563.988281\n",
      "         Iterations: 10\n",
      "         Function evaluations: 142\n",
      "         Gradient evaluations: 139\n",
      "         Hessian evaluations: 43\n",
      "Inverse HVP took 3.36470413208 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000540971755981 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013454406\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044133044\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.044760715\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0048947018\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.252317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [21] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.0913211 0.9086789]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.0913211 0.9086789]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 61 perturbation shape: (1, 268203), perturbation: [[ 1.02701163  2.17327523  0.2909306  ... -3.38453221  1.90840316\n",
      "   0.37080121]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -34719.632812\n",
      "         Iterations: 9\n",
      "         Function evaluations: 83\n",
      "         Gradient evaluations: 80\n",
      "         Hessian evaluations: 45\n",
      "Inverse HVP took 2.21374607086 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000516891479492 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.0134668145\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.00441678\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.045096684\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0049878005\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.254417\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.08883708 0.911163  ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.08883708 0.911163  ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [37] iter.\n",
      "After training with LBFGS: \n",
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 62 perturbation shape: (1, 268203), perturbation: [[-1.54014838 -0.05024457  0.89452815 ... -0.47439921 -0.60686451\n",
      "   0.67352033]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -34933.921875\n",
      "         Iterations: 8\n",
      "         Function evaluations: 62\n",
      "         Gradient evaluations: 59\n",
      "         Hessian evaluations: 38\n",
      "Inverse HVP took 1.72995901108 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000585079193115 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013464913\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044181263\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.045062315\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004913591\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.253654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [23] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.08536801 0.914632  ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.08536801 0.914632  ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 63 perturbation shape: (1, 268203), perturbation: [[ 0.91967195  2.37130713 -1.23581517 ... -2.01292229  1.50376868\n",
      "   0.37480468]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -35082.593750\n",
      "         Iterations: 8\n",
      "         Function evaluations: 84\n",
      "         Gradient evaluations: 80\n",
      "         Hessian evaluations: 40\n",
      "Inverse HVP took 2.12182211876 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000530004501343 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013487281\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044248966\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.045226887\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.005022415\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.25732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [39] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.08291344 0.91708654]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.08291344 0.91708654]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 64 perturbation shape: (1, 268203), perturbation: [[-1.78977227  0.2484704   1.75294769 ... -1.47840905 -0.30596399\n",
      "   1.23176193]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -35297.851562\n",
      "         Iterations: 8\n",
      "         Function evaluations: 80\n",
      "         Gradient evaluations: 76\n",
      "         Hessian evaluations: 40\n",
      "Inverse HVP took 2.06752610207 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000530958175659 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013475286\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044222237\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.045162268\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.004924932\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.255129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [21] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.08026694 0.9197331 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.08026694 0.9197331 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 65 perturbation shape: (1, 268203), perturbation: [[ 0.91018516  2.261904   -1.0860554  ... -0.16064757  1.2536211\n",
      "  -0.38311523]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -35389.835938\n",
      "         Iterations: 10\n",
      "         Function evaluations: 234\n",
      "         Gradient evaluations: 227\n",
      "         Hessian evaluations: 50\n",
      "Inverse HVP took 5.27015304565 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000517129898071 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013504017\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044320715\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.045495994\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0050558127\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.259565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [38] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.07788751 0.9221125 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.07788751 0.9221125 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 66 perturbation shape: (1, 268203), perturbation: [[-3.76700425  0.04639414  1.58612454 ... -2.02778459  0.24035126\n",
      "   1.04130423]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -35599.234375\n",
      "         Iterations: 9\n",
      "         Function evaluations: 167\n",
      "         Gradient evaluations: 162\n",
      "         Hessian evaluations: 42\n",
      "Inverse HVP took 3.87561511993 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000530958175659 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013488082\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044272817\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04530646\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0049491646\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2569475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [41] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.07598885 0.9240111 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.07598885 0.9240111 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 67 perturbation shape: (1, 268203), perturbation: [[ 1.26994121  2.77085614  0.0514047  ... -2.91776299  1.61074114\n",
      "  -0.66187435]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -35649.781250\n",
      "         Iterations: 9\n",
      "         Function evaluations: 78\n",
      "         Gradient evaluations: 75\n",
      "         Hessian evaluations: 43\n",
      "Inverse HVP took 2.23179292679 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000571966171265 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013512971\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044364096\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.045622338\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0050512566\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2606487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [37] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.07389872 0.9261013 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.07389872 0.9261013 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 68 perturbation shape: (1, 268203), perturbation: [[-1.95185018  0.31972057  1.64643645 ...  0.51165104 -0.46737576\n",
      "   1.66666114]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -35817.007812\n",
      "         Iterations: 8\n",
      "         Function evaluations: 70\n",
      "         Gradient evaluations: 67\n",
      "         Hessian evaluations: 34\n",
      "Inverse HVP took 1.79523515701 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000596046447754 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013507868\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004434732\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.045585666\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0050138934\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.259845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [32] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.07198282 0.9280172 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.07198282 0.9280172 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 69 perturbation shape: (1, 268203), perturbation: [[ 0.41920757  2.06408381 -0.04659178 ... -3.37002325  0.55655134\n",
      "   0.22239554]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -35924.492188\n",
      "         Iterations: 9\n",
      "         Function evaluations: 67\n",
      "         Gradient evaluations: 65\n",
      "         Hessian evaluations: 46\n",
      "Inverse HVP took 1.86314487457 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000509023666382 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013519511\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.00443976\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.045592405\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.005033205\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2613964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [35] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.07089911 0.9291008 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.07089911 0.9291008 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 70 perturbation shape: (1, 268203), perturbation: [[-0.98679805  0.37634343  0.27160716 ...  0.58208752 -0.1184193\n",
      "   1.31447315]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -35956.757812\n",
      "         Iterations: 8\n",
      "         Function evaluations: 152\n",
      "         Gradient evaluations: 145\n",
      "         Hessian evaluations: 38\n",
      "Inverse HVP took 3.48405218124 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.00051212310791 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013525091\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044417647\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.045832038\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0050762473\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2622356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [45] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.06935931 0.9306407 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.06935931 0.9306407 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 71 perturbation shape: (1, 268203), perturbation: [[-0.64151305  2.12985134  0.86332822 ... -2.92642188  1.21644366\n",
      "  -0.34356242]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -36113.105469\n",
      "         Iterations: 9\n",
      "         Function evaluations: 74\n",
      "         Gradient evaluations: 71\n",
      "         Hessian evaluations: 40\n",
      "Inverse HVP took 1.91731905937 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000525951385498 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013529054\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004443815\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.045636173\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0050423793\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2626843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [23] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.06769733 0.9323027 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.06769733 0.9323027 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 72 perturbation shape: (1, 268203), perturbation: [[ 0.52141547  0.62322998 -0.1047025  ...  0.63814843  0.4564327\n",
      "   0.08970141]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -36130.203125\n",
      "         Iterations: 8\n",
      "         Function evaluations: 84\n",
      "         Gradient evaluations: 81\n",
      "         Hessian evaluations: 39\n",
      "Inverse HVP took 2.12628102303 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.00053596496582 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013537498\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044470173\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.045951236\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0051061516\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.263914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [46] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.06607737 0.93392265]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.06607737 0.93392265]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 73 perturbation shape: (1, 268203), perturbation: [[-0.74450111  2.29572105  1.03481388 ... -3.67584801  0.24459803\n",
      "   1.19918585]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -36312.296875\n",
      "         Iterations: 8\n",
      "         Function evaluations: 55\n",
      "         Gradient evaluations: 51\n",
      "         Hessian evaluations: 38\n",
      "Inverse HVP took 1.51653194427 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000522136688232 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013543189\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004449775\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.045736793\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.005063041\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.264601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [23] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.06381045 0.9361896 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.06381045 0.9361896 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 74 perturbation shape: (1, 268203), perturbation: [[ 0.25989079  0.16063297 -0.45863092 ...  1.16300392  0.8579582\n",
      "  -0.1303173 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -36345.312500\n",
      "         Iterations: 10\n",
      "         Function evaluations: 77\n",
      "         Gradient evaluations: 75\n",
      "         Hessian evaluations: 49\n",
      "Inverse HVP took 2.27736520767 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000582933425903 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013555122\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004454314\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.046171576\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.00513903\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2663355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [40] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.06228418 0.9377158 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.06228418 0.9377158 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 75 perturbation shape: (1, 268203), perturbation: [[-2.55876517  1.99355185  1.6051389  ... -2.65320206  0.25011057\n",
      "   0.9510169 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -36540.640625\n",
      "         Iterations: 8\n",
      "         Function evaluations: 93\n",
      "         Gradient evaluations: 89\n",
      "         Hessian evaluations: 37\n",
      "Inverse HVP took 2.31099200249 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000529050827026 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013549607\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044526183\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.045886453\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0050645988\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.26544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [44] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.06019495 0.9398051 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.06019495 0.9398051 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 76 perturbation shape: (1, 268203), perturbation: [[-0.02676535  1.18732953  0.31128582 ...  0.73794383  1.46457207\n",
      "  -0.47044301]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -36538.769531\n",
      "         Iterations: 10\n",
      "         Function evaluations: 74\n",
      "         Gradient evaluations: 73\n",
      "         Hessian evaluations: 54\n",
      "Inverse HVP took 2.13504004478 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000524997711182 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013570418\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004460466\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04619599\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0051563387\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.268478\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.05892804 0.9410719 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.05892804 0.9410719 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [45] iter.\n",
      "After training with LBFGS: \n",
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 77 perturbation shape: (1, 268203), perturbation: [[-1.25246847  1.66337335  0.57372975 ... -2.18019247 -0.06200123\n",
      "   1.11924601]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -36728.429688\n",
      "         Iterations: 9\n",
      "         Function evaluations: 126\n",
      "         Gradient evaluations: 122\n",
      "         Hessian evaluations: 43\n",
      "Inverse HVP took 3.08610701561 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000554084777832 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013565665\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004458861\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.046016835\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.005102682\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2677402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [22] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.05738651 0.94261354]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.05738651 0.94261354]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 78 perturbation shape: (1, 268203), perturbation: [[-0.62403047  1.77773404  1.89101756 ...  0.31468493  1.4973526\n",
      "  -0.93389928]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -36692.250000\n",
      "         Iterations: 8\n",
      "         Function evaluations: 106\n",
      "         Gradient evaluations: 102\n",
      "         Hessian evaluations: 40\n",
      "Inverse HVP took 2.56232905388 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000514984130859 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013579255\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044641388\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04637794\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.005169132\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.269687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [39] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.05642306 0.9435769 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.05642306 0.9435769 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 79 perturbation shape: (1, 268203), perturbation: [[-0.09887731  1.01625633 -0.49224538 ... -2.98377252  0.21645829\n",
      "   0.96730763]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -36865.257812\n",
      "         Iterations: 9\n",
      "         Function evaluations: 79\n",
      "         Gradient evaluations: 76\n",
      "         Hessian evaluations: 48\n",
      "Inverse HVP took 2.14120817184 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000521898269653 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013578299\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004464283\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.046151493\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.005124267\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.269429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [22] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.05484738 0.94515264]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.05484738 0.94515264]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 80 perturbation shape: (1, 268203), perturbation: [[-1.22335529  2.04733324  1.9766717  ...  1.25077224  2.08656788\n",
      "  -1.45829046]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -36827.082031\n",
      "         Iterations: 11\n",
      "         Function evaluations: 216\n",
      "         Gradient evaluations: 212\n",
      "         Hessian evaluations: 52\n",
      "Inverse HVP took 4.97536706924 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000510931015015 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013590066\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044681593\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04639359\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.005186594\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2712774\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.05377449 0.9462255 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.05377449 0.9462255 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [32] iter.\n",
      "After training with LBFGS: \n",
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 81 perturbation shape: (1, 268203), perturbation: [[-0.67747331  1.27252448 -0.42507493 ... -2.53037715 -0.08989996\n",
      "   0.84128696]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -37000.656250\n",
      "         Iterations: 8\n",
      "         Function evaluations: 98\n",
      "         Gradient evaluations: 94\n",
      "         Hessian evaluations: 38\n",
      "Inverse HVP took 2.37237477303 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000570058822632 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013590049\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004469061\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.0463476\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0051585888\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.271063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [19] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.05261055 0.9473895 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.05261055 0.9473895 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 82 perturbation shape: (1, 268203), perturbation: [[-0.30782676  0.53865671 -0.24478519 ...  0.09862331  1.75642037\n",
      "  -0.08096045]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -36946.015625\n",
      "         Iterations: 8\n",
      "         Function evaluations: 87\n",
      "         Gradient evaluations: 83\n",
      "         Hessian evaluations: 39\n",
      "Inverse HVP took 2.22854399681 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000540018081665 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013596667\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044713044\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.046347793\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0051806024\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2720866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [34] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.05161491 0.94838506]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.05161491 0.94838506]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 83 perturbation shape: (1, 268203), perturbation: [[-0.67162484  0.77683794 -0.67080045 ... -0.7275067  -0.13057223\n",
      "  -0.31246996]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -37106.636719\n",
      "         Iterations: 10\n",
      "         Function evaluations: 155\n",
      "         Gradient evaluations: 151\n",
      "         Hessian evaluations: 55\n",
      "Inverse HVP took 3.79608201981 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.00055193901062 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013599956\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004473262\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04654218\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.005193988\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2723985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [24] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.05044089 0.9495591 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.05044089 0.9495591 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 84 perturbation shape: (1, 268203), perturbation: [[-1.54531288  0.87639576  0.89249098 ... -1.68390048  2.17689705\n",
      "   1.18273544]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -37068.875000\n",
      "         Iterations: 9\n",
      "         Function evaluations: 90\n",
      "         Gradient evaluations: 88\n",
      "         Hessian evaluations: 41\n",
      "Inverse HVP took 2.31820893288 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.00052809715271 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013601915\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044733444\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.046332404\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.005175385\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2728376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [20] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.04973082 0.9502692 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.04973082 0.9502692 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 85 perturbation shape: (1, 268203), perturbation: [[-0.00827944  1.00116134 -1.51971257 ...  0.67980409 -0.49651143\n",
      "  -0.84527862]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -37197.554688\n",
      "         Iterations: 8\n",
      "         Function evaluations: 85\n",
      "         Gradient evaluations: 81\n",
      "         Hessian evaluations: 42\n",
      "Inverse HVP took 2.19545602798 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000519037246704 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013614314\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004479204\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.046798006\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.00523285\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2743673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [36] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.0482031  0.95179695]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.0482031  0.95179695]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 86 perturbation shape: (1, 268203), perturbation: [[-3.08226776  0.94592535  2.11254454 ... -2.31526303  2.09514618\n",
      "   0.68983412]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -37203.324219\n",
      "         Iterations: 8\n",
      "         Function evaluations: 95\n",
      "         Gradient evaluations: 91\n",
      "         Hessian evaluations: 42\n",
      "Inverse HVP took 2.42290902138 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000509977340698 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [35] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013608031\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044757617\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04635163\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0051732883\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.273703\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.04750386 0.9524962 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.04750386 0.9524962 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 87 perturbation shape: (1, 268203), perturbation: [[ 1.0126574  -0.14161849 -3.20075941 ... -0.74927109  0.03915782\n",
      "  -0.64656538]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -37287.980469\n",
      "         Iterations: 7\n",
      "         Function evaluations: 78\n",
      "         Gradient evaluations: 74\n",
      "         Hessian evaluations: 35\n",
      "Inverse HVP took 2.08215498924 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000515937805176 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013626032\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004484488\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.046919163\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0052529317\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.275872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [42] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.04612411 0.9538759 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.04612411 0.9538759 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 88 perturbation shape: (1, 268203), perturbation: [[-2.82489395  2.59474826  3.25140738 ... -1.05791283  1.79621816\n",
      "   0.1636177 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -37307.921875\n",
      "         Iterations: 11\n",
      "         Function evaluations: 160\n",
      "         Gradient evaluations: 157\n",
      "         Hessian evaluations: 58\n",
      "Inverse HVP took 3.91363596916 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000526905059814 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [21] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013618555\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044797626\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.046399765\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.005187884\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2752295\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.04538696 0.9546131 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.04538696 0.9546131 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 89 perturbation shape: (1, 268203), perturbation: [[ 1.16953504 -1.41211867 -4.46968031 ... -1.06956923 -0.70327538\n",
      "  -0.44729334]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -37384.277344\n",
      "         Iterations: 8\n",
      "         Function evaluations: 88\n",
      "         Gradient evaluations: 84\n",
      "         Hessian evaluations: 39\n",
      "Inverse HVP took 2.35324788094 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.00051212310791 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.0136351045\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004488704\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.047086194\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.005255328\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2770076\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.04426225 0.95573777]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.04426225 0.95573777]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [36] iter.\n",
      "After training with LBFGS: \n",
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 90 perturbation shape: (1, 268203), perturbation: [[-2.10045695  2.54577804  2.59677339 ... -0.95353544  1.9673115\n",
      "   0.19045185]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -37393.929688\n",
      "         Iterations: 8\n",
      "         Function evaluations: 79\n",
      "         Gradient evaluations: 75\n",
      "         Hessian evaluations: 39\n",
      "Inverse HVP took 1.99652004242 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000514030456543 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013624666\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044821803\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.046441205\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0052045407\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.276093\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.04365246 0.9563475 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.04365246 0.9563475 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [34] iter.\n",
      "After training with LBFGS: \n",
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 91 perturbation shape: (1, 268203), perturbation: [[ 0.47526073 -1.06561232 -3.83369613 ... -0.93168622 -0.73103899\n",
      "  -0.28537416]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -37471.140625\n",
      "         Iterations: 9\n",
      "         Function evaluations: 151\n",
      "         Gradient evaluations: 147\n",
      "         Hessian evaluations: 46\n",
      "Inverse HVP took 3.57750797272 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000508069992065 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013645783\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044932594\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04715637\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.005263215\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.278439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [39] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.04268108 0.95731884]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.04268108 0.95731884]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 92 perturbation shape: (1, 268203), perturbation: [[-2.02889395  1.99163532  1.36558437 ... -0.79067916  1.58820963\n",
      "   1.13516307]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -37460.214844\n",
      "         Iterations: 9\n",
      "         Function evaluations: 73\n",
      "         Gradient evaluations: 72\n",
      "         Hessian evaluations: 49\n",
      "Inverse HVP took 2.03496909142 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000514984130859 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.01362953\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044845\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04656726\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0052251793\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2766876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [43] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.04219284 0.9578071 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.04219284 0.9578071 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 93 perturbation shape: (1, 268203), perturbation: [[ 0.78887701 -0.07383585 -2.67866898 ... -0.61045909 -0.25338644\n",
      "  -0.84078288]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -37547.199219\n",
      "         Iterations: 8\n",
      "         Function evaluations: 71\n",
      "         Gradient evaluations: 68\n",
      "         Hessian evaluations: 42\n",
      "Inverse HVP took 1.88454794884 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000521898269653 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013653517\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004496562\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04713089\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0052664285\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.279475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [43] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.04133819 0.9586618 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.04133819 0.9586618 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 94 perturbation shape: (1, 268203), perturbation: [[-0.89065969  1.46575785 -0.0544402  ... -0.27436462  0.62107396\n",
      "   1.1563431 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -37516.617188\n",
      "         Iterations: 12\n",
      "         Function evaluations: 26\n",
      "         Gradient evaluations: 37\n",
      "         Hessian evaluations: 78\n",
      "Inverse HVP took 1.49876999855 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000509977340698 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013642788\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044892966\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.046770953\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.005264879\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.278665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [31] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.04071212 0.9592879 ]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.04071212 0.9592879 ]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 95 perturbation shape: (1, 268203), perturbation: [[-0.94809574  0.26057443 -1.24222648 ... -1.19920921 -0.34283867\n",
      "  -0.11874503]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -37622.007812\n",
      "         Iterations: 8\n",
      "         Function evaluations: 82\n",
      "         Gradient evaluations: 78\n",
      "         Hessian evaluations: 38\n",
      "Inverse HVP took 2.0707089901 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000531911849976 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013657613\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004498328\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.047100626\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.005273002\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2800193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [37] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.0399533 0.9600467]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.0399533 0.9600467]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 96 perturbation shape: (1, 268203), perturbation: [[-0.1170702   0.14862001 -0.83391774 ... -0.32968125  1.05322576\n",
      "   0.44667113]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -37566.031250\n",
      "         Iterations: 9\n",
      "         Function evaluations: 143\n",
      "         Gradient evaluations: 138\n",
      "         Hessian evaluations: 43\n",
      "Inverse HVP took 3.41948699951 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000520944595337 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013655638\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044945357\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.046915833\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.005291842\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.280445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [24] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.03904483 0.96095514]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.03904483 0.96095514]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 97 perturbation shape: (1, 268203), perturbation: [[-0.45785987  0.86184204 -1.73966837 ... -1.21109021 -0.38100469\n",
      "   0.93912697]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -37698.562500\n",
      "         Iterations: 10\n",
      "         Function evaluations: 133\n",
      "         Gradient evaluations: 130\n",
      "         Hessian evaluations: 56\n",
      "Inverse HVP took 3.31730103493 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000524044036865 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013660381\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.0044994378\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.047122836\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0052766274\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.280407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [33] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.03888858 0.96111137]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.03888858 0.96111137]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 98 perturbation shape: (1, 268203), perturbation: [[-1.54946327 -0.29508138  0.93007928 ...  1.15923476  0.58144373\n",
      "  -0.09927906]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -37613.453125\n",
      "         Iterations: 11\n",
      "         Function evaluations: 193\n",
      "         Gradient evaluations: 186\n",
      "         Hessian evaluations: 64\n",
      "Inverse HVP took 4.6229300499 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000516891479492 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n",
      "Shape (1, 2048)\n",
      "Using normal model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013665458\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004498392\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.047132626\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0053300806\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.281837\n",
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.03789109 0.96210885]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.03789109 0.96210885]]\n",
      "[iter_attack.py:138 -     iterative_attack() ] *** Iter: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [38] iter.\n",
      "After training with LBFGS: \n",
      "Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:160 -     iterative_attack() ] Attach_iter 99 perturbation shape: (1, 268203), perturbation: [[ 0.0405162   1.58749163 -1.87807417 ... -3.19072056 -0.71753657\n",
      "   3.30716562]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -37746.640625\n",
      "         Iterations: 10\n",
      "         Function evaluations: 153\n",
      "         Gradient evaluations: 146\n",
      "         Hessian evaluations: 55\n",
      "Inverse HVP took 3.69466900826 sec\n",
      "Loaded inverse HVP from output/poisoning_900_300_inception_wd-0.001-test-[45].npz\n",
      "Inverse HVP took 0.000514984130859 sec\n",
      "Entering the for loop\n",
      "(1, 268203)\n",
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:328 -     print_model_eval() ] Train loss (w reg) on all data: 0.013667375\n",
      "[genericNeuralNet.py:329 -     print_model_eval() ] Train loss (w/o reg) on all data: 0.004501966\n",
      "[genericNeuralNet.py:331 -     print_model_eval() ] Test loss (w/o reg) on all data: 0.04704576\n",
      "[genericNeuralNet.py:332 -     print_model_eval() ] Train acc on all data:  1.0\n",
      "[genericNeuralNet.py:333 -     print_model_eval() ] Test acc on all data:   0.985\n",
      "[genericNeuralNet.py:335 -     print_model_eval() ] Norm of the mean of gradients: 0.0052796495\n",
      "[genericNeuralNet.py:336 -     print_model_eval() ] Norm of the params: 4.2814503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1, 2048)\n",
      "Using normal model\n",
      "LBFGS training took [21] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[iter_attack.py:204 -     iterative_attack() ] Test_idx: 45 Test pred (full): [[0.03766986 0.96233016]]\n",
      "[iter_attack.py:205 -     iterative_attack() ] ---------------------\n",
      "[iter_attack.py:210 -     iterative_attack() ] Test_idx: 45 Test pred (top): [[0.03766986 0.96233016]]\n"
     ]
    }
   ],
   "source": [
    "# 1. Poison the dataset \n",
    "target_idx, poisoned_image = data_poisoning(['dog', 'fish'], 900, 300, True, target_test_idx, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading animals from disk...\n",
      "../data/dataset_dog-fish_train-900_test-300.npz\n",
      "self.logits Tensor(\"Shape:0\", shape=(2,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[genericNeuralNet.py:191 -   get_vec_to_list_fn() ] Total number of parameters: 2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong_labels_bool Tensor(\"Shape_2:0\", shape=(2,), dtype=int32)\n",
      "logits Tensor(\"Shape_3:0\", shape=(2,), dtype=int32)\n",
      "inception_features:  Tensor(\"flatten/Reshape:0\", shape=(?, ?), dtype=float32)\n",
      "x_poison_features:  Tensor(\"Gather:0\", shape=(1, ?), dtype=float32)\n",
      "t_target_features:  Tensor(\"Gather_1:0\", shape=(1, ?), dtype=float32)\n",
      "Lp:  Tensor(\"norm/Squeeze:0\", shape=(), dtype=float32)\n",
      "LP_gradient Tensor(\"strided_slice_1:0\", shape=(268203,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 2. Generate all the inception features\n",
    "\n",
    "# Find the cleaned dataset\n",
    "data_sets = load_animals(\n",
    "                    num_train_ex_per_class=num_train_ex_per_class, \n",
    "                    num_test_ex_per_class=num_test_ex_per_class,\n",
    "                    classes=data_selected)\n",
    "\n",
    "# Replace the target training point with the poisoned one\n",
    "poisoned_dataset_x = np.copy(data_sets.train.x)\n",
    "poisoned_dataset_x[target_idx] = poisoned_image # data_sets.test.x[15] \n",
    "poisoned_dataset_labels = data_sets.train.labels\n",
    "\n",
    "poisoned_dataset = DataSet(poisoned_dataset_x, poisoned_dataset_labels)\n",
    "\n",
    "# Create the DateSet that only contain the target test point\n",
    "target_test_dataset = DataSet(data_sets.test.x[target_test_idx], data_sets.test.labels[target_test_idx])\n",
    "\n",
    "# Create the clean and poisoned training inception features\n",
    "# and the inception feature of the target test point\n",
    "img_side = 299\n",
    "num_channels = 3\n",
    " \n",
    "initial_learning_rate = 0.001 \n",
    "keep_probs = None\n",
    "decay_epochs = [1000, 10000]\n",
    "\n",
    "weight_decay = 0.001\n",
    "\n",
    "num_classes = len(data_selected)\n",
    "max_lbfgs_iter = 1000\n",
    "batch_size = 50\n",
    "\n",
    "dataset_name = 'transferbility_%s_%s' % (num_train_ex_per_class, num_test_ex_per_class)\n",
    "\n",
    "full_graph = tf.Graph()\n",
    "with full_graph.as_default():\n",
    "    full_model_name = '%s_inception_wd-%s' % (dataset_name, weight_decay)\n",
    "    full_model = BinaryInceptionModel(\n",
    "        img_side=img_side,\n",
    "        num_channels=num_channels,\n",
    "        weight_decay=weight_decay,\n",
    "        num_classes=num_classes, \n",
    "        batch_size=batch_size,\n",
    "        data_sets=data_sets,\n",
    "        initial_learning_rate=initial_learning_rate,\n",
    "        keep_probs=keep_probs,\n",
    "        decay_epochs=decay_epochs,\n",
    "        mini_batch=True,\n",
    "        train_dir='output',\n",
    "        log_dir='log',\n",
    "        model_name=full_model_name)\n",
    "    \n",
    "    clean_inception_features = full_model.generate_inception_features(data_sets.train, None)\n",
    "    poisoned_inception_features = full_model.generate_inception_features(poisoned_dataset, None)\n",
    "    target_test_inception_features = full_model.generate_inception_features(target_test_dataset, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('True label of target test point: ', array([0.]))\n",
      "('Inital prediction (Log Reg): ', array([0.]))\n",
      "('Final prediction (Log Reg): ', array([1.]))\n",
      "('Inital prediction (SVM): ', array([0.]))\n",
      "('Final prediction (SVM): ', array([1.]))\n"
     ]
    }
   ],
   "source": [
    "# 3. Feed to SVM and check if flips or not \n",
    "#    To compare, also show the results of Log Reg\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "C = 1.0 / (len(data_sets.train.x) * weight_decay)  \n",
    "if num_classes == 2:\n",
    "    log_reg_model = LogisticRegression(\n",
    "                C=C,\n",
    "                tol=1e-8,\n",
    "                fit_intercept=False, \n",
    "                solver='lbfgs',\n",
    "                warm_start=True, #True\n",
    "                max_iter=max_lbfgs_iter)\n",
    "else:\n",
    "    log_reg_model = LogisticRegression(\n",
    "                C=C,\n",
    "                tol=1e-8,\n",
    "                fit_intercept=False, \n",
    "                solver='lbfgs',\n",
    "                multi_class='multinomial',\n",
    "                warm_start=True, #True\n",
    "                max_iter=max_lbfgs_iter) \n",
    "    \n",
    "svc_model = SVC(\n",
    "                C=C,\n",
    "                kernel='linear'\n",
    "                )\n",
    "\n",
    "print(\"True label of target test point: \", data_sets.test.labels[target_test_idx])\n",
    "log_reg_model.fit(clean_inception_features, data_sets.train.labels)\n",
    "print(\"Inital prediction (Log Reg): \", log_reg_model.predict(target_test_inception_features))\n",
    "log_reg_model.fit(poisoned_inception_features, data_sets.train.labels)\n",
    "print(\"Final prediction (Log Reg): \", log_reg_model.predict(target_test_inception_features))\n",
    "\n",
    "svc_model.fit(clean_inception_features, data_sets.train.labels)\n",
    "print(\"Inital prediction (SVM): \", svc_model.predict(target_test_inception_features))\n",
    "svc_model.fit(poisoned_inception_features, data_sets.train.labels)\n",
    "print(\"Final prediction (SVM): \", svc_model.predict(target_test_inception_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:influence_env]",
   "language": "python",
   "name": "conda-env-influence_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
